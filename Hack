{"metadata": {"language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "nbconvert_exporter": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "name": "python", "version": "3.5.2"}, "kernelspec": {"display_name": "Python 3.5 (Experimental) with Spark 2.0", "language": "python", "name": "python3-spark20"}}, "nbformat": 4, "cells": [{"outputs": [{"output_type": "stream", "text": "Collecting pika\n  Downloading pika-0.10.0-py2.py3-none-any.whl (92kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 102kB 2.6MB/s \n\u001b[?25hInstalling collected packages: pika\nSuccessfully installed pika-0.10.0\n", "name": "stdout"}], "metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 31, "source": "!pip install pika"}, {"outputs": [], "metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 1, "source": "from pyspark.sql import SQLContext\n#SQLContext\nsqlContext = SQLContext(sc)\n#load rss from cloudant\ndef load():\n    hackathonb = sqlContext.read.format(\"com.cloudant.spark\").\\\n    option(\"cloudant.host\",\"\").\\\n    option(\"cloudant.username\", \"asaddingtheentleforandst\") .\\\n    option(\"cloudant.password\",\"6ce711095559185e8c65e21078afa51214703092\").\\\n    option(\"inferSchema\", \"true\").\\\n    load(\"hackathonb\")\n    return hackathonb "}, {"outputs": [{"output_type": "stream", "text": "+--------------------+--------------------+---+---+---+---+---------+\n|                 _id|                _rev| a1| a2| a3| a4|    uname|\n+--------------------+--------------------+---+---+---+---+---------+\n|06b898d08496f634b...|1-47d23ade2d77942...|  1|  4|  3|  3|  \u3044\u3068\u3046\u3053\u3046\u3044\u3061|\n|08a6499a3193f4198...|1-8f8ca2fb14dcd5f...|  4|  4|  4|  4|       \u307e\u306a|\n|08a6499a3193f4198...|1-2874dfec6c7d93e...|  1|  2|  4|  3|     \u305f\u306a\u304b\u3086|\n|0a8d3672f0c3f5109...|1-a4339446a416934...|  4|  4|  4|  1| \u304d\u3087\u3046\u3060\u307e\u3055\u3072\u308d|\n|1f9294901725f32d4...|1-61a5efe933bf65c...|  1|  1|  3|  3|  \u306a\u307f\u304d\u3055\u304f\u3089\u3053|\n|287e3786eaba3cc23...|1-e5a38325e81a37e...|  3|  2|  2|  3|    \u305f\u306a\u304b\u30862|\n|28ec2b705f004e02e...|1-ec09c95c69c9f8a...|  1|  4|  3|  4| \u304a\u304a\u3064\u304b\u3068\u3082\u3072\u3053|\n|28ec2b705f004e02e...|1-b3974b4625f60e1...|  3|  3|  3|  3|   \u3059\u305a\u304d\u3068\u304a\u308b|\n|4cd2baa3b82e798d7...|1-e1c09c9172ef952...|  2|  4|  2|  3|       \u6817\u539f|\n|733282bda39924d7a...|1-4ed393e43e26c47...|  1|  4|  2|  4|Nishikawa|\n|8c33da1d660b7136c...|1-d1f4ea2be9e286c...|  1|  4|  1|  3|   \u304b\u3044\u3058\u307e\u305d\u3046|\n|9c5bb6ebf360dffe6...|1-d1f4ea2be9e286c...|  1|  4|  1|  3|   \u304b\u3044\u3058\u307e\u305d\u3046|\n|9c5bb6ebf360dffe6...|1-e21d2f69b09f400...|  1|  3|  1|  2|   \u307b\u305d\u304b\u305a\u3072\u3055|\n|9c9f905d58d3650ed...|1-eca66b61ce9ba5e...|  3|  4|  3|  1|    \u3059\u305a\u304d\u307f\u304b|\n|ab7b2b3a9fbb22424...|1-2832b35b5c52f69...|  2|  4|  3|  3|       :)|\n|b54b8f6c7fd00d76e...|1-8e82a2dbf5c0a32...|  3|  2|  1|  4|     \u304a\u304b\u3050\u3061|\n|cea8dae3d8b0b50bb...|1-5c5d069c0b0bcf0...|  1|  2|  2|  3|    \u305b\u304d\u3042\u3064\u3057|\n|df01d6d04990e0b62...|1-5e100dffad059e9...|  2|  4|  4|  3|       \u4eca\u91ce|\n|df01d6d04990e0b62...|1-979517255142c0e...|  3|  1|  3|  4|  \u3088\u3064\u3082\u3068\u306a\u3064\u307f|\n|e0cc661dca2e9075b...|1-b066b4e174f6a83...|  1|  4|  3|  3|  \u306f\u3057\u3082\u3068\u3053\u3046\u3058|\n+--------------------+--------------------+---+---+---+---+---------+\nonly showing top 20 rows\n\n", "name": "stdout"}], "metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 2, "source": "load().show()"}, {"outputs": [], "metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 3, "source": "from pyspark.ml.linalg import Vectors\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.sql.types import DoubleType\n\ndef cast_df(hackathonb):\n    cast1 = hackathonb.withColumn(\"a1\", hackathonb[\"a1\"].cast(DoubleType()))\n    cast2 = cast1.withColumn(\"a2\", cast1[\"a2\"].cast(DoubleType()))\n    cast3 = cast2.withColumn(\"a3\", cast2[\"a2\"].cast(DoubleType()))\n    cast4 = cast3.withColumn(\"a4\", cast3[\"a4\"].cast(DoubleType()))\n    return cast4\n\n#cast4.printSchema()\ndef normarize(inpul):\n    assembler = VectorAssembler(inputCols=[\"a1\",\"a2\",\"a3\",\"a4\"], outputCol=\"features\")\n    feature_vectors = assembler.transform(inpul)\n    return feature_vectors.select([\"uname\",\"a1\",\"a2\",\"a3\",\"a4\",\"features\"])"}, {"outputs": [], "metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 4, "source": "from pyspark.ml.feature import StandardScaler\n\ndef standardization(inpul):\n    scaler = StandardScaler(inputCol=\"features\", outputCol=\"standardization\", withStd=True, withMean=True)\n    scalerModel = scaler.fit(inpul)\n    return scalerModel.transform(inpul)\n\n#\u6a19\u6e96\u5316\u5909\u91cf\u3060\u3051\u8868\u793a\n#print(\"==== \u6a19\u6e96\u5316\u3055\u308c\u305f\u30c7\u30fc\u30bf ====\")\n#std_feature_vectors.select(\"standardization\").show(truncate=False)"}, {"outputs": [], "metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 5, "source": "from pyspark.ml.feature import PCA\n\ndef cPCA(inpul):\n    pca = PCA(k=2, inputCol=\"standardization\", outputCol=\"pca\")\n    return pca.fit(inpul)\n\n#print(\"==== \u56fa\u6709\u30d9\u30af\u30c8\u30eb ====\")\n#print(pcaModel.pc)\n\n#print(\"==== \u5bc4\u4e0e\u7387 ====\")\n#print(pcaModel.explainedVariance)\n\n#pca_score = pcaModel.transform(std_feature_vectors).select([\"uname\",\"pca\"])\n#print(\"==== \u4e3b\u6210\u5206\u5f97\u70b9 ====\")\n#pca_score.show(truncate=False)"}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 6, "source": "import math\ndef sigmoid(z):\n    return 1/(1+math.e**(-z)) "}, {"outputs": [], "metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 10, "source": "import pika  \nimport sys  \nimport ssl\n\ntry:  \n    from urllib import urlencode\nexcept ImportError:  \n    from urllib.parse import urlencode\n    \ndef publish(data):\n    ssl_opts = \"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURlekNDQW1PZ0F3SUJBZ0lFV0k2S0FEQU5CZ2txaGtpRzl3MEJBUTBGQURBL01UMHdPd1lEVlFRREREUjUKZFdsamFHbDBia0JxY0M1cFltMHVZMjl0TFRka1pXWmxNbVpqTWpSaE1URmlOekJoTWpFd01qSXhNalprWWpJMwpaV1E0TUI0WERURTNNREV6TURBd016UXdPRm9YRFRNM01ERXpNREF3TURBd01Gb3dQekU5TURzR0ExVUVBd3cwCmVYVnBZMmhwZEc1QWFuQXVhV0p0TG1OdmJTMDNaR1ZtWlRKbVl6STBZVEV4WWpjd1lUSXhNREl5TVRJMlpHSXkKTjJWa09EQ0NBU0l3RFFZSktvWklodmNOQVFFQkJRQURnZ0VQQURDQ0FRb0NnZ0VCQUxITm9GQlZONUJKaUY5UwpabWEvaVFYelM3RjNnY1ZxZXYzTkh4a1g0REFQOUUrd3p0R3FuTGVlZUpoSWp1K291QUwvMlcrNmhudDJNczBzCllEby9Dak0yYWZtVTlmeldGN21YbGxNWjFKaDRRaW5pMk5qdEp0VjJwN3FBcmx0Vk9ncHA3ZEVZNHFkUTBWejkKbGM0SkFZRWNqZzBvTUxNeFFTWmkvK24vZFgzczNzNlVTMWtoNCt0SUp5cVVVYTRaR1dQdlNUc3ZxaDViRzhsaQpkM2VWQWt6dnhSci9FRUdzYXMvOHdaNC9yY2puU3Z5Q3hmV1hoZjR1R1p4akVQSWg0OVVYVGFMd0FRMjhYN3hMCjdCd00vMXNua0FUaGdvOXgzNzVDV3JUM3dSWHpBSURhdGZQcDV0a2pqMU1QZ2kxbUdTdUMxU1hhdEJObGZkNEcKcXpKVXVXY0NBd0VBQWFOL01IMHdIUVlEVlIwT0JCWUVGTXRnOGFZTGlBQS9HdytsQ2xieWlxSktzSUhvTUE0RwpBMVVkRHdFQi93UUVBd0lDQkRBZEJnTlZIU1VFRmpBVUJnZ3JCZ0VGQlFjREFRWUlLd1lCQlFVSEF3SXdEQVlEClZSMFRCQVV3QXdFQi96QWZCZ05WSFNNRUdEQVdnQlRMWVBHbUM0Z0FQeHNQcFFwVzhvcWlTckNCNkRBTkJna3EKaGtpRzl3MEJBUTBGQUFPQ0FRRUFJYXd4TWNkblNCVG9pV2JOeEVVY1VIc3p3Q1k3WXZVRWdkS2xpT2JWQUJhRApmSmVNSWVDS056OEhtYmQ1dzRsTStmaEN0bXFuclBYK09abFJ2dGpLTHlZTmp1OGRYTmtDK2tXT0I4QjZBdU0rCjdQRTlFNm5wemlGTEovZGNEWVdmRDd5SkpHb2h2YW51bTdDZGhwMHhPMkQ3QWNwdnc3cElkMjhUSFdkOTQyRGUKZnRabFdpWGtUWk12ck9UUXFGMk5nY1RBUVgvUHJrdFl4cnRQK2lSZDJlOVVXK0NpQlFxT1B0L283bWMwUEJlNgphMk5VYUFCaDB3dS9HWXBkN1V0cnREc3ZrN0tZSkMrenVXZ1FscDYwZzJ6MGJPaTdEN242ZWd1cVE1VDFxakpLCjJydjUrYUhKN2dPSFdzNDV6UVFnUUlyNmdKVE82ZFBpQ1FuTmZhTlpTQT09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K\"\n    full_url='amqps://admin:UHBNFRYPESQJNNEG@bluemix-sandbox-dal-9-portal.0.dblayer.com:22646/bmix_dal_yp_c006c6d6_a709_477e_9b4c_e02e6579032f?'+ssl_opts  \n    parameters = pika.URLParameters(full_url)\n    connection = pika.BlockingConnection(parameters)  \n    channel = connection.channel()\n    message='[' + data + ']'  \n    my_routing_key='hello'  \n    channel.basic_publish(exchange='',  \n                      routing_key=my_routing_key,\n                      body=message)\n    channel.close()  \n    connection.close()  "}, {"outputs": [{"output_type": "stream", "text": "+---------+------------------------------------------+\n|uname    |pca                                       |\n+---------+------------------------------------------+\n|\u3044\u3068\u3046\u3053\u3046\u3044\u3061  |[-1.1693208107988877,0.7852481697522389]  |\n|\u307e\u306a       |[-1.037410105388899,-0.6178333689186624]  |\n|\u305f\u306a\u304b\u3086     |[1.5332470774812448,0.7020287213659421]   |\n|\u304d\u3087\u3046\u3060\u307e\u3055\u3072\u308d |[-1.2347133326234716,-2.708740693537448]  |\n|\u306a\u307f\u304d\u3055\u304f\u3089\u3053  |[2.884531021621311,0.6604189971727937]    |\n|\u305f\u306a\u304b\u30862    |[1.5773423861468878,-0.6980050432188332]  |\n|\u304a\u304a\u3064\u304b\u3068\u3082\u3072\u3053 |[-1.1035530683873636,1.4822172779585006]  |\n|\u3059\u305a\u304d\u3068\u304a\u308b   |[0.2260584420068216,-0.6563953190256847]  |\n|\u6817\u539f       |[-1.147273156466066,0.08523128745985117]  |\n|Nishikawa|[-1.1035530683873636,1.4822172779585006]  |\n|\u304b\u3044\u3058\u307e\u305d\u3046   |[-1.1693208107988877,0.7852481697522389]  |\n|\u304b\u3044\u3058\u307e\u305d\u3046   |[-1.1693208107988877,0.7852481697522389]  |\n|\u307b\u305d\u304b\u305a\u3072\u3055   |[0.11619539092965436,0.04666933735282863] |\n|\u3059\u305a\u304d\u307f\u304b    |[-1.256760986956293,-2.0087238112450603]  |\n|:)       |[-1.147273156466066,0.08523128745985117]  |\n|\u304a\u304b\u3050\u3061     |[1.643110128558412,-0.0010359350125713762]|\n|\u305b\u304d\u3042\u3064\u3057    |[1.5332470774812448,0.7020287213659421]   |\n|\u4eca\u91ce       |[-1.147273156466066,0.08523128745985117]  |\n|\u3088\u3064\u3082\u3068\u306a\u3064\u307f  |[2.9943940726984777,-0.04264565920571972] |\n|\u306f\u3057\u3082\u3068\u3053\u3046\u3058  |[-1.1693208107988877,0.7852481697522389]  |\n+---------+------------------------------------------+\nonly showing top 20 rows\n\n", "name": "stdout"}], "metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 11, "source": "cloudant_df = load()\ninput_df = cast_df(cloudant_df)\nt_input_df = normarize(input_df)\nsta_df = standardization(t_input_df)\nmodel = cPCA(sta_df)\nmodel.transform(sta_df).select([\"uname\",\"pca\"]).show(truncate=False)\nlst_res = model.transform(sta_df).select([\"uname\",\"pca\"]).rdd.collect()"}, {"outputs": [{"output_type": "stream", "text": "run\n[-1.1693208108,0.785248169752]\n[-1.03741010539,-0.617833368919]\n[1.53324707748,0.702028721366]\n[-1.23471333262,-2.70874069354]\n[2.88453102162,0.660418997173]\n[1.57734238615,-0.698005043219]\n[-1.10355306839,1.48221727796]\n[0.226058442007,-0.656395319026]\n[-1.14727315647,0.0852312874599]\n[-1.10355306839,1.48221727796]\n[-1.1693208108,0.785248169752]\n[-1.1693208108,0.785248169752]\n[0.11619539093,0.0466693373528]\n[-1.25676098696,-2.00872381125]\n[-1.14727315647,0.0852312874599]\n[1.64311012856,-0.00103593501257]\n[1.53324707748,0.702028721366]\n[-1.14727315647,0.0852312874599]\n[2.9943940727,-0.0426456592057]\n[-1.1693208108,0.785248169752]\n[1.59901481989,1.39899782957]\n[0.226058442007,-0.656395319026]\n[0.204010787674,0.0436215632667]\n[-1.14727315647,0.0852312874599]\n[-1.27880864129,-1.30870692895]\n[-1.10355306839,1.48221727796]\n[1.44580690132,-2.09194325963]\n[1.40171159266,-0.691909495047]\n", "name": "stdout"}], "metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 12, "source": "import time\ndef run():\n    print (\"run\")\n    cloudant_df = load()\n    input_df = cast_df(cloudant_df)\n    t_input_df = normarize(input_df)\n    sta_df = standardization(t_input_df)\n    model = cPCA(sta_df)\n    lst_res = model.transform(sta_df).select([\"uname\",\"pca\"]).rdd.collect()\n    lst_sorted = sorted(lst_res)\n    str_list = [\"{\\\"lbl\\\":\\\"\" + x.uname + \"\\\",\\\"val\\\":[\" + str(sigmoid(x.pca[0]+((i+1) * 1/11)) * 700) + \",\" + str(sigmoid(x.pca[1]+((i+1) * 1/10)) * 700) + \"]}\" for (i,x) in enumerate(lst_sorted)]\n    publish(','.join(str_list))\n    [print(x.pca) for x in lst_res]\nrun()   \n"}, {"outputs": [{"output_type": "stream", "text": "run\nrun\nrun\nrun\nrun\nrun\nrun\nrun\nrun\nrun\nrun\nrun\nrun\nrun\nrun\n", "name": "stdout"}, {"output_type": "error", "traceback": ["\u001b[1;31m\u001b[0m", "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)", "\u001b[1;32m<ipython-input-16-f88b484a1075>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[1;31mKeyboardInterrupt\u001b[0m: "], "ename": "KeyboardInterrupt", "evalue": ""}], "metadata": {"collapsed": false}, "cell_type": "code", "execution_count": 16, "source": "import time\ndef run():\n    print (\"run\")\n    cloudant_df = load()\n    input_df = cast_df(cloudant_df)\n    t_input_df = normarize(input_df)\n    sta_df = standardization(t_input_df)\n    model = cPCA(sta_df)\n    lst_res = model.transform(sta_df).select([\"uname\",\"pca\"]).rdd.collect()\n    lst_sorted = sorted(lst_res)\n    str_list = [\"{\\\"lbl\\\":\\\"\" + x.uname + \"\\\",\\\"val\\\":[\" + str(sigmoid(x.pca[0]+((i+1) * 1/11)) * 700) + \",\" + str(sigmoid(x.pca[1]+((i+1) * 1/10)) * 700) + \"]}\" for (i,x) in enumerate(lst_sorted)]\n    #print(str_list)\n    publish(','.join(str_list))\n    #[print(x.pca) for x in lst_res]\n#run()   \nwhile True:\n    run()\n    time.sleep(1)"}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "execution_count": null, "source": ""}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "execution_count": null, "source": ""}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "execution_count": null, "source": ""}], "nbformat_minor": 0}
